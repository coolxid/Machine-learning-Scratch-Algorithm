{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Text Classification (Sentiment Analysis) Using Bayes Rule \n",
    "\n",
    "In this task we wil implement a Naive Bayes Multinomial classifier using  bag of words model for the classification of text (movie reviews) into different categories..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string(string): # Parse a read string into respective tokens\n",
    "\n",
    "    like=(re.sub(\"<.*?>\", \"\",string[0]))\n",
    "    tokens=re.findall(r'[\\w+\\'\\w+]|\\w+',like)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(filename): # Parse a given file\n",
    "    \n",
    "    with open(filename,'r') as rfile:\n",
    "        rstring=rfile.read()\n",
    "    \n",
    "    return rstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_strings(X):\n",
    "\n",
    "    rX=np.zeros((X.shape[0],1),dtype=object)\n",
    "    for ei in range(X.shape[0]):\n",
    "        rX[ei,0]=parse_file(X[ei][0])\n",
    "        \n",
    "    return rX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    ''' Implements the Naive Bayes For Text Classification... '''\n",
    "    def __init__(self, classes):\n",
    "        self.classes=classes\n",
    "    def prior(self,lables):\n",
    "        prior=[]\n",
    "        classesFrequency=[]\n",
    "        length=len(self.classes)\n",
    "        for ind in range(length):\n",
    "            classesFrequency.append(list(lables).count(self.classes[ind]))\n",
    "            prior.append(float(classesFrequency[ind])/len(lables))\n",
    "        return prior\n",
    "    \n",
    "    def splitClasses(self,X,Y):\n",
    "        splitClass=[]\n",
    "        for l in range(len(self.classes)):\n",
    "            index=(Y==self.classes[l])\n",
    "            list=X[index]\n",
    "            splitClass.append(list)\n",
    "        return splitClass\n",
    "    \n",
    "    def train(self, trainData, Y):\n",
    "        # now go and train a model for each class...\n",
    "        #Creating vocabulary of training data....\n",
    "        posVocabulary=[]\n",
    "        negVocabulary=[]\n",
    "        feature,length,h=np.shape(trainData)\n",
    "        for index in range(length):\n",
    "            token=parse_string(trainData[0][index])\n",
    "            negVocabulary.append(token)\n",
    "            token=parse_string(trainData[1][index])\n",
    "            posVocabulary.append(token)\n",
    "        \n",
    "        positive=np.concatenate(posVocabulary,axis=0)\n",
    "        negative=np.concatenate(negVocabulary,axis=0)\n",
    "\n",
    "        positiveUnique=np.unique(positive)\n",
    "        negativeUnique=np.unique(negative)\n",
    "\n",
    "        Vocalbulary=[negative,positive]\n",
    "        uniqueVocalbulary=[negativeUnique,positiveUnique]\n",
    "        vocalbularyOrignalLengths=[len(negative),len(positive)]\n",
    "        vocalbularyUniqueLengths=[len(negativeUnique),len(positiveUnique)]\n",
    "        return Vocalbulary,uniqueVocalbulary,vocalbularyOrignalLengths,vocalbularyUniqueLengths\n",
    "    \n",
    "    def test(self,testData,prior,v,uv,vol,vul):\n",
    "            \n",
    "        nexamples, nfeatures=testData.shape\n",
    "        pclasses=[0]*nexamples\n",
    "        # your code go here...\n",
    "        neg = Counter(v[0])\n",
    "        pos = Counter(v[1])\n",
    "        print classes\n",
    "        print \"---------------Dictionary Done----------------\"\n",
    "        for inx in range(nexamples):#picking up file one by one\n",
    "            token=parse_string(testData[inx])#parsing the picked file\n",
    "            prob=[]\n",
    "            for ine in range(len(self.classes)): #loop for types of reviews(first neg,then positive)\n",
    "                likelyHood=0\n",
    "                for ind in range(len(token)): #loop for each token of the file one by one\n",
    "                    if (ine==0):\n",
    "                        key=token[ind]\n",
    "                        frequency=neg.get(key,0)\n",
    "                    else:\n",
    "                        key=token[ind]\n",
    "                        frequency=pos.get(key,0)\n",
    "                    num=frequency+1    \n",
    "                    denom=vol[ine]+np.sum(vul)\n",
    "                    likelyhood=float(num)/denom\n",
    "                    lh=np.log(likelyhood)\n",
    "                    likelyHood=lh+likelyHood \n",
    "                pr=np.log(prior[ine])\n",
    "                probablity=pr+likelyHood \n",
    "                prob.append(probablity) \n",
    "            maxi=prob.index(max(prob))\n",
    "            pclasses[inx]=self.classes[maxi] \n",
    "        return np.array(pclasses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tools as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews =  1000\n",
      "Number of negative reviews =  1000\n"
     ]
    }
   ],
   "source": [
    "tdir='./data1/imdb1/' # training dir...\n",
    "#load data, get list of files for each class...\n",
    "posfiles=t.get_files(tdir+'/pos','*',withpath=True)\n",
    "negfiles=t.get_files(tdir+'/neg','*',withpath=True)\n",
    "pos=len(posfiles)\n",
    "neg=len(negfiles)\n",
    "print 'Number of positive reviews = ', pos\n",
    "print 'Number of negative reviews = ', neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Dimensions = (2000L, 1L)  Training labels dimensions= (2000L,)\n"
     ]
    }
   ],
   "source": [
    "#generate training and testing data...\n",
    "plabels=['pos']*len(posfiles)\n",
    "nlabels=['neg']*len(posfiles)\n",
    "labels=np.concatenate((plabels,nlabels)) # concatenate the +ve and -ve labels\n",
    "tX=np.concatenate((posfiles,negfiles)).reshape((len(posfiles)+len(negfiles),1))\n",
    "print \"Training data Dimensions =\", tX.shape,\" Training labels dimensions=\", labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=file_to_strings(tX) # read files and convert each file into set of strings and return an numpy array\n",
    "#Split the data into two halves training and test set...\n",
    "traindata,trainlabels,testdata,testlabels=t.split_data(tX,labels)\n",
    "#Find the classes to train\n",
    "classes=np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] training a classifier for following classes neg, pos\n",
      "-------------Test--------------\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "------------------Print ACC---------------------\n",
      "[Info] Accuracy = 0.836666666667\n"
     ]
    }
   ],
   "source": [
    "#Now build a Naive Bayes classifir and test it...\n",
    "print '[Info] training a classifier for following classes {}, {}'.format(classes[0],classes[1])\n",
    "nb=NaiveBayes(classes)\n",
    "testData=file_to_strings(testdata)\n",
    "trainData=file_to_strings(traindata)\n",
    "prior=nb.prior(labels)\n",
    "split=nb.splitClasses(trainData,trainlabels)\n",
    "v,uv,vol,vul=nb.train(split,trainlabels)\n",
    "print \"-------------Test--------------\"\n",
    "pclasses=nb.test(testData,prior,v,uv,vol,vul)\n",
    "acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "print \"------------------Print ACC---------------------\"\n",
    "print \"[Info] Accuracy = {}\".format(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation\n",
    "\n",
    "Now lets throw our methods to winds of different folds and measure their accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CV data for 2 classes\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n",
      "(1800L, 1L) (200L, 1L)\n"
     ]
    }
   ],
   "source": [
    "#Now lets generate n-fold training and testing data...\n",
    "\n",
    "nfolds=10\n",
    "folds=t.generate_folds(X,labels,nfolds) # generate folds for \n",
    "for k in arange(len(folds)):\n",
    "    print folds[k][0].shape, folds[k][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 1 Accuracy = 0.795\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 2 Accuracy = 0.82\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 3 Accuracy = 0.785\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 4 Accuracy = 0.815\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 5 Accuracy = 0.825\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 6 Accuracy = 0.775\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 7 Accuracy = 0.81\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 8 Accuracy = 0.805\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 9 Accuracy = 0.825\n",
      "['neg' 'pos']\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 10 Accuracy = 0.83\n",
      "[0.79500000000000004, 0.81999999999999995, 0.78500000000000003, 0.81499999999999995, 0.82499999999999996, 0.77500000000000002, 0.81000000000000005, 0.80500000000000005, 0.82499999999999996, 0.82999999999999996]\n",
      "[Info] Mean Accuracy = 0.8085\n"
     ]
    }
   ],
   "source": [
    "totacc=[]\n",
    "#train a classifier for each fold...\n",
    "classes=np.unique(labels)\n",
    "\n",
    "for k in range(nfolds):\n",
    "    nb=NaiveBayes(classes)\n",
    "    prior=nb.prior(labels)\n",
    "    traindata=folds[k][0]\n",
    "    trainlabels=folds[k][1]\n",
    "    testdata=folds[k][2]\n",
    "    testlabels=folds[k][3]\n",
    "    \n",
    "    #Lets first train the classifier\n",
    "    split=nb.splitClasses(traindata,trainlabels)\n",
    "    v,uv,vol,vul=nb.train(split,trainlabels)\n",
    "    \n",
    "    #Lets test the classifier\n",
    "    pclasses= nb.test(testdata,prior,v,uv,vol,vul)\n",
    "    \n",
    "    acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "    print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)    \n",
    "    \n",
    "    totacc.append(acc)\n",
    "\n",
    "print totacc\n",
    "print '[Info] Mean Accuracy =', np.mean(totacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Excellent, now its time to dive into deep waters of Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data-set\n",
    "train=pd.read_csv('./kaggle/labeledTrainData.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td> 25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>     0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>     0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>     0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>     0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>     0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>     1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>     1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "count  25000.00000\n",
       "mean       0.50000\n",
       "std        0.50001\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.50000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 5814_8</td>\n",
       "      <td> 1</td>\n",
       "      <td> With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2381_9</td>\n",
       "      <td> 1</td>\n",
       "      <td> \\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 7759_3</td>\n",
       "      <td> 0</td>\n",
       "      <td> The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 3630_4</td>\n",
       "      <td> 0</td>\n",
       "      <td> It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 9495_8</td>\n",
       "      <td> 1</td>\n",
       "      <td> Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000L,)\n"
     ]
    }
   ],
   "source": [
    "Yt=train['sentiment']\n",
    "Xt=train['review']\n",
    "Xt=np.array(Xt)\n",
    "Yt=np.array(Yt)\n",
    "print Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test set...\n",
    "test=pd.read_csv('./kaggle/testData.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 12311_10</td>\n",
       "      <td> Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>   8348_2</td>\n",
       "      <td> This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>   5828_4</td>\n",
       "      <td> All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>   7186_2</td>\n",
       "      <td> Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  12128_7</td>\n",
       "      <td> A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Training Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the training data into two halves and test our accuracy...\n",
    "traindata,trainlabels,testdata,testlabels=t.split_data(Xt.reshape((Xt.shape[0],1)),Yt)\n",
    "classes=np.unique(trainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] training a classifier for following classes 0, 1\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Accuracy = 0.615866666667\n"
     ]
    }
   ],
   "source": [
    "# Now lets go and train the model and see its performance...\n",
    "print '[Info] training a classifier for following classes {}, {}'.format(classes[0],classes[1])\n",
    "nb=NaiveBayes(classes)\n",
    "prior=nb.prior(Yt)\n",
    "split=nb.splitClasses(traindata,trainlabels)\n",
    "l,lu,ol,ul=nb.train(split,trainlabels)\n",
    "pclasses=nb.test(testdata,prior,l,lu,ol,ul)\n",
    "acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "print \"[Info] Accuracy = {}\".format(acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation Time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CV data for 2 classes\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n",
      "(22500L, 1L) (2500L, 1L)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into 10 folds and test classifiers performance...\n",
    "\n",
    "nfolds=10\n",
    "folds=t.generate_folds(Xt.reshape((Xt.shape[0],1)),Yt,nfolds) # generate folds for \n",
    "for k in arange(len(folds)):\n",
    "    print folds[k][0].shape, folds[k][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 1 Accuracy = 0.8508\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 2 Accuracy = 0.8392\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 3 Accuracy = 0.85\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 4 Accuracy = 0.8408\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 5 Accuracy = 0.8664\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 6 Accuracy = 0.8476\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 7 Accuracy = 0.8632\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 8 Accuracy = 0.8496\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 9 Accuracy = 0.8432\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "[Info] Fold 10 Accuracy = 0.8396\n",
      "[0.8508, 0.83919999999999995, 0.84999999999999998, 0.84079999999999999, 0.86639999999999995, 0.84760000000000002, 0.86319999999999997, 0.84960000000000002, 0.84319999999999995, 0.83960000000000001]\n",
      "[Info] Mean Accuracy = 0.84904\n"
     ]
    }
   ],
   "source": [
    "# As it takes time, so becareful it can cause your machine into red hot oven\n",
    "totacc=[]\n",
    "classes=np.unique(Yt)\n",
    "\n",
    "for k in range(nfolds):\n",
    "    nb=NaiveBayes(classes)\n",
    "    prior=nb.prior(Yt)\n",
    "    traindata=folds[k][0]\n",
    "    trainlabels=folds[k][1]\n",
    "    \n",
    "    #Lets first train the classifier\n",
    "    split=nb.splitClasses(traindata,trainlabels)\n",
    "    l,lu,ol,ul=nb.train(split,trainlabels)\n",
    "    \n",
    "    testdata=folds[k][2]\n",
    "    testlabels=folds[k][3]\n",
    "    \n",
    "    #Lets test the classifier\n",
    "    pclasses= nb.test(testdata,prior,l,lu,ol,ul)\n",
    "    \n",
    "    acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "    print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)    \n",
    "    \n",
    "    totacc.append(acc)\n",
    "\n",
    "print totacc\n",
    "print '[Info] Mean Accuracy =', np.mean(totacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's train on the complete dataset and test on the provided test set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Classifier on Full training set with classes = [0 1]\n",
      "(2L, 12500L, 1L)\n",
      "------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "classes= np.unique(Yt)\n",
    "print 'Training a Classifier on Full training set with classes =', classes\n",
    "nb=NaiveBayes(classes)\n",
    "prior=nb.prior(Yt)\n",
    "split=nb.splitClasses(Xt.reshape(Xt.shape[0],1),Yt)\n",
    "print np.shape(split)\n",
    "l,lu,ol,ul=nb.train(split,Yt)\n",
    "print \"------------Done--------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Start---------------\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "#Get the test data...\n",
    "print \"------------Start---------------\"\n",
    "Xtest=test['review']\n",
    "Xtest=np.array(Xtest.reshape((Xtest.shape[0],1)))\n",
    "#test the classifier on the provided test set...\n",
    "pclasses=nb.test(Xtest,prior,l,lu,ol,ul)\n",
    "print \"------------Done--------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the result in the kaggle's required format\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":pclasses} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"./kaggle/Naive_bays_Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to Upload the prediction to Kaggle...\n",
    "\n",
    "Now upload the result on the Kaggle and see your ranking and score. Using this simple method you can have an accuracy of around 0.80960."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Improvement by Excluding Stop Words...\n",
    "\n",
    "You can improve your score further by excluding the commonly occuring words (also known as stop words) in the English language.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Classifier on Full training set with classes = [0 1]\n",
      "(2L, 12500L, 1L)\n",
      "----------------Stop Words Removed-------------\n",
      "------------Done--------------\n",
      "------------Start---------------\n",
      "[0 1]\n",
      "---------------Dictionary Done----------------\n",
      "------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "#read and create a set of stop \n",
    "stopwords=set(t.read_txt_file('./data1/english.stop'))\n",
    "#print stopwords\n",
    "#--------------------Training-----------------------------\n",
    "classes= np.unique(Yt)\n",
    "print 'Training a Classifier on Full training set with classes =', classes\n",
    "nb=NaiveBayes(classes)\n",
    "prior=nb.prior(Yt)\n",
    "split=nb.splitClasses(Xt.reshape(Xt.shape[0],1),Yt)\n",
    "print np.shape(split)\n",
    "l,lu,ol,ul=nb.train(split,Yt)\n",
    "li.append( [item for item in l[0] if item not in stopwords])\n",
    "li.append([item for item in l[1] if item not in stopwords])\n",
    "print \"----------------Stop Words Removed-------------\"\n",
    "print \"------------Done--------------\"\n",
    "#--------------------Testing-----------------------------\n",
    "#Get the test data...\n",
    "print \"------------Start---------------\"\n",
    "Xtest=test['review']\n",
    "Xtest=np.array(Xtest.reshape((Xtest.shape[0],1)))\n",
    "#test the classifier on the provided test set...\n",
    "pclasses=nb.test(Xtest,prior,li,lu,ol,ul)\n",
    "print \"------------Done--------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":pclasses} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"./kaggle/Naive_bays_Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
